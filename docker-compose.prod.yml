services:
  # ── Database ─────────────────────────────────────────────────
  postgres:
    image: postgres:16-alpine
    restart: unless-stopped
    environment:
      POSTGRES_USER: ${POSTGRES_USER:-blueth}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:?Set POSTGRES_PASSWORD in .env}
      POSTGRES_DB: ${POSTGRES_DB:-blueth_city}
    ports:
      - '5432:5432'
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ['CMD-SHELL', 'pg_isready -U ${POSTGRES_USER:-blueth}']
      interval: 10s
      timeout: 5s
      retries: 5
    logging:
      driver: json-file
      options:
        max-size: '10m'
        max-file: '3'

  # ── Migrations (one-shot) ────────────────────────────────────
  migrate:
    build:
      context: .
      dockerfile: ./apps/api/Dockerfile
      args:
        GIT_COMMIT: ${GIT_COMMIT:-unknown}
    command: ['node', 'packages/db/dist/migrate.js']
    environment:
      DATABASE_URL: ${DATABASE_URL}
    depends_on:
      postgres:
        condition: service_healthy
    restart: 'no'
    logging:
      driver: json-file
      options:
        max-size: '10m'
        max-file: '3'

  # ── API Server ───────────────────────────────────────────────
  api:
    build:
      context: .
      dockerfile: ./apps/api/Dockerfile
      args:
        GIT_COMMIT: ${GIT_COMMIT:-unknown}
    restart: unless-stopped
    environment:
      NODE_ENV: production
      DATABASE_URL: ${DATABASE_URL}
      PORT: ${PORT:-3001}
      HOST: 0.0.0.0
      ALLOWED_ORIGINS: ${ALLOWED_ORIGINS:-}
      LOG_LEVEL: ${LOG_LEVEL:-info}
      GIT_COMMIT: ${GIT_COMMIT:-unknown}
    ports:
      - '${PORT:-3001}:${PORT:-3001}'
    depends_on:
      migrate:
        condition: service_completed_successfully
    healthcheck:
      test: ['CMD', 'wget', '--no-verbose', '--tries=1', '--spider', 'http://127.0.0.1:${PORT:-3001}/health']
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 10s
    logging:
      driver: json-file
      options:
        max-size: '10m'
        max-file: '3'

  # ── Scheduler Worker ─────────────────────────────────────────
  scheduler:
    build:
      context: .
      dockerfile: ./apps/api/Dockerfile
      args:
        GIT_COMMIT: ${GIT_COMMIT:-unknown}
    command: ['node', 'apps/api/dist/workers/scheduler.js']
    restart: unless-stopped
    environment:
      NODE_ENV: production
      DATABASE_URL: ${DATABASE_URL}
      SCHEDULER_POLL_MS: ${SCHEDULER_POLL_MS:-5000}
      LOG_LEVEL: ${LOG_LEVEL:-info}
      GIT_COMMIT: ${GIT_COMMIT:-unknown}
    depends_on:
      migrate:
        condition: service_completed_successfully
    logging:
      driver: json-file
      options:
        max-size: '10m'
        max-file: '3'

  # ── Tick Worker ──────────────────────────────────────────────
  # WARNING: Run exactly ONE tick worker instance.
  # The tick table provides idempotency via UNIQUE(tick_type, tick_timestamp),
  # but multiple instances cause unnecessary contention.
  tick:
    build:
      context: .
      dockerfile: ./apps/api/Dockerfile
      args:
        GIT_COMMIT: ${GIT_COMMIT:-unknown}
    command: ['node', 'apps/api/dist/workers/tick.js']
    restart: unless-stopped
    environment:
      NODE_ENV: production
      DATABASE_URL: ${DATABASE_URL}
      TICK_POLL_MS: ${TICK_POLL_MS:-10000}
      LOG_LEVEL: ${LOG_LEVEL:-info}
      GIT_COMMIT: ${GIT_COMMIT:-unknown}
    depends_on:
      migrate:
        condition: service_completed_successfully
    deploy:
      replicas: 1
    logging:
      driver: json-file
      options:
        max-size: '10m'
        max-file: '3'

  # ── Web (Next.js) ────────────────────────────────────────────
  web:
    build:
      context: .
      dockerfile: ./apps/web/Dockerfile
      args:
        NEXT_PUBLIC_API_URL: ''
        API_INTERNAL_URL: http://api:3001
        GIT_COMMIT: ${GIT_COMMIT:-unknown}
    restart: unless-stopped
    environment:
      NODE_ENV: production
      GIT_COMMIT: ${GIT_COMMIT:-unknown}
    ports:
      - '${WEB_PORT:-3000}:3000'
    depends_on:
      - api
    healthcheck:
      test: ['CMD', 'wget', '--no-verbose', '--tries=1', '--spider', 'http://127.0.0.1:3000/']
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 15s
    logging:
      driver: json-file
      options:
        max-size: '10m'
        max-file: '3'

  # ── Caddy Reverse Proxy ────────────────────────────────────
  caddy:
    image: caddy:2-alpine
    restart: unless-stopped
    ports:
      - '80:80'
      - '443:443'
      - '443:443/udp'
    environment:
      API_DOMAIN: ${API_DOMAIN:-api.localhost}
      WEB_DOMAIN: ${WEB_DOMAIN:-localhost}
    volumes:
      - ./Caddyfile:/etc/caddy/Caddyfile:ro
      - caddy_data:/data
      - caddy_config:/config
    depends_on:
      api:
        condition: service_healthy
    logging:
      driver: json-file
      options:
        max-size: '10m'
        max-file: '3'

volumes:
  postgres_data:
  caddy_data:
  caddy_config:
